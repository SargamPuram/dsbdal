ğŸ“˜ Viva Questions & Answers
1. What is Naive Bayes?
A probabilistic classifier based on Bayes' Theorem with the naive assumption that all features are independent.

2. Why use Gaussian Naive Bayes?
Because it handles continuous, normally distributed features â€” perfect for datasets like Iris.

3. Bayes' Theorem formula?
ğ‘ƒ
(
ğ‘Œ
âˆ£
ğ‘‹
)
=
ğ‘ƒ
(
ğ‘‹
âˆ£
ğ‘Œ
)
â‹…
ğ‘ƒ
(
ğ‘Œ
)
ğ‘ƒ
(
ğ‘‹
)
P(Yâˆ£X)= 
P(X)
P(Xâˆ£Y)â‹…P(Y)
â€‹
 
4. Why encode the target variable?
Because ML models can only work with numerical values, not strings.

5. Why do we scale the features?
To make all features contribute equally â€” especially important in distance-based or probabilistic models.

6. What does the confusion matrix show?
Class	TP	FP	FN
Setosa (0)	10	0	0
Versicolor (1)	9	0	0
Virginica (2)	11	0	0

7. What are:
TP (True Positive): Correctly classified as its own class

FP (False Positive): Incorrectly classified as this class

FN (False Negative): Belongs to the class but classified wrongly

TN (True Negative): Not of this class and correctly not predicted as it

8. Metric Formulas:
Accuracy:

Accuracy
=
ğ‘‡
ğ‘ƒ
+
ğ‘‡
ğ‘
ğ‘‡
ğ‘ƒ
+
ğ¹
ğ‘ƒ
+
ğ‘‡
ğ‘
+
ğ¹
ğ‘
Accuracy= 
TP+FP+TN+FN
TP+TN
â€‹
 
Precision (Macro):

Precision
=
1
ğ¶
âˆ‘
ğ‘‡
ğ‘ƒ
ğ‘–
ğ‘‡
ğ‘ƒ
ğ‘–
+
ğ¹
ğ‘ƒ
ğ‘–
Precision= 
C
1
â€‹
 âˆ‘ 
TP 
i
â€‹
 +FP 
i
â€‹
 
TP 
i
â€‹
 
â€‹
 
Recall (Macro):

Recall
=
1
ğ¶
âˆ‘
ğ‘‡
ğ‘ƒ
ğ‘–
ğ‘‡
ğ‘ƒ
ğ‘–
+
ğ¹
ğ‘
ğ‘–
Recall= 
C
1
â€‹
 âˆ‘ 
TP 
i
â€‹
 +FN 
i
â€‹
 
TP 
i
â€‹
 
â€‹
 
Error Rate:

1
âˆ’
Accuracy
1âˆ’Accuracy
9. Is 100% accuracy realistic?
Not always. In real-world noisy data, it's rare. In clean, small datasets like Iris, it can happen. But it's always worth questioning.

âœ… Conclusion
The Naive Bayes classifier achieved perfect performance on the Iris dataset. It shows how powerful simple probabilistic models can be when data is clean, structured, and balanced.
